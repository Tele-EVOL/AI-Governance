# Awesome AI Governance

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![Stars](https://img.shields.io/github/stars/YourRepo/Awesome-AI-Governance)](https://github.com/YourRepo/Awesome-AI-Governance/stargazers)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

## Introduction

This repository serves as a comprehensive and structured collection of resources on **AI Governance**. [cite_start]The rapid advancement of AI has introduced complex technical vulnerabilities and societal risks, underscoring the pressing need for a holistic governance framework[cite: 10, 11]. [cite_start]This collection is organized according to the principles outlined in our survey, "[Never Compromise to Vulnerabilities: A Comprehensive Survey on Al Governance](https://example.com/link_to_your_paper.pdf)," which integrates technical methodologies, evaluation benchmarks, and policy perspectives[cite: 14].

[cite_start]Our framework categorizes AI Governance into three interconnected pillars[cite: 13]:
* [cite_start]**Intrinsic Security**: Focusing on internal system reliability and robustness[cite: 13, 62, 152].
* [cite_start]**Derivative Security**: Addressing external, real-world harms arising from AI deployment[cite: 13, 62, 281].
* [cite_start]**Social Ethics**: Centered on value alignment, accountability, and societal impact[cite: 13, 62].

[cite_start]This repository aims to provide researchers, engineers, and policymakers with a curated list of papers, toolkits, and benchmarks to design AI systems that are not only high-performing but also secure, ethical, and aligned with public trust[cite: 20].

- This repo is a living document and is actively being updated :seedling:.
- **Badges:**
    - **Model:**
        - ![LLM](https://img.shields.io/badge/LLM-589cf4)
        - ![VLM](https://img.shields.io/badge/VLM-c7688b)
        - ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
        - ![Agent](https://img.shields.io/badge/Agent-964B00)
    - **Tag:** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![Defense](https://img.shields.io/badge/Defense-87b800) ![Policy](https://img.shields.io/badge/Policy-87b800) ![Evaluation](https://img.shields.io/badge/Evaluation-87b800) ![Framework](https://img.shields.io/badge/Framework-87b800) ![Dataset](https://img.shields.io/badge/Dataset-87b800)
    - **Venue:** ![TPAMI](https://img.shields.io/badge/TPAMI-f1b800) ![CVPR](https://img.shields.io/badge/CVPR-f1b800) ![ICCV](https://img.shields.io/badge/ICCV-f1b800) ![ACL](https://img.shields.io/badge/ACL-f1b800) ![NeurIPS](https://img.shields.io/badge/NeurIPS-f1b800) ![ICML](https://img.shields.io/badge/ICML-f1b800) ![USENIX](https://img.shields.io/badge/USENIX-f1b800)

:sunflower: We welcome contributions! Please feel free to open a pull request or issue to add more resources using the following format:

| Title | Link | Code | Venue | Classification | Model | Tag |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Paper Title | arxiv | github | Venue'YY | 1.1 Adversarial Vulnerability | LLM | Defense |

---
## News
- **[2025.08.08]** &#x1f680; Repository launched! The structure is based on the AI Governance framework from our TPAMI 2025 survey.

## Collections
- [Survey](collection/survey.md) (XX)
- [Toolkit](collection/toolkit.md) (XX)
- [Leaderboard](collection/leaderboard.md) (XX)
- [Book](collection/book.md) (XX)
- **Paper** (XXXX)
    - **1. Intrinsic Security** (XXX)
        - [1.1 Adversarial Vulnerability](collection/paper/intrinsic_security/adversarial_vulnerability.md) (XX)
        - [1.2 Robustness](collection/paper/intrinsic_security/robustness.md) (XX)
        - [1.3 Hallucination](collection/paper/intrinsic_security/hallucination.md) (XX)
        - [1.4 Interpretability](collection/paper/intrinsic_security/interpretability.md) (XX)
    - **2. Derivative Security** (XXX)
        - [2.1 Privacy Risks](collection/paper/derivative_security/privacy.md) (XX)
        - [2.2 Bias & Discrimination](collection/paper/derivative_security/bias_discrimination.md) (XX)
        - [2.3 Abuse & Misuse](collection/paper/derivative_security/abuse_misuse.md) (XX)
    - **3. Social Ethics** (XXX)
        - [3.1 Social & Economic Impact](collection/paper/social_ethics/social_economic_impact.md) (XX)
        - [3.2 Ethical & Legal Issues](collection/paper/social_ethics/ethical_legal.md) (XX)
        - [3.3 Responsibility & Accountability](collection/paper/social_ethics/responsibility_accountability.md) (XX)

## Thank you to our contributors! üôè

[![Star History Chart](https://api.star-history.com/svg?repos=YourRepo/Awesome-AI-Governance&type=Date)](https://star-history.com/#YourRepo/Awesome-AI-Governance&Date)

## Acknowledgement

This repository is maintained by the authors of the survey "Never Compromise to Vulnerabilities: A Comprehensive Survey on Al Governance" (TPAMI 2025). The taxonomy and organization are derived directly from this work. We are inspired by the open-source spirit of repositories like [Awesome-LM-SSP](https://github.com/ThuCCSLab/Awesome-LM-SSP), [LLM Security](https://llmsecurity.net/), and [Awesome LLM Security](https://github.com/corca-ai/awesome-llm-security).
