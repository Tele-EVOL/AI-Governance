# Bias & Discrimination

- [2024/08] **[A Survey of Trojan Attacks and Defenses to Deep Neural Networks](https://arxiv.org/abs/2408.08920)** ![Defense](https://img.shields.io/badge/Defense-87b800)

- [2024/04] **[Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs](https://arxiv.org/abs/2404.10160)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)

- [2024/02] **[MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots](https://www.ndss-symposium.org/ndss-paper/masterkey-automated-jailbreaking-of-large-language-model-chatbots/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Safety](https://img.shields.io/badge/Safety-87b800) ![NDSS](https://img.shields.io/badge/NDSS-f1b800)

- [2023/02] **[Attacks in Adversarial Machine Learning: A Systematic Survey from the Life-cycle Perspective](https://arxiv.org/abs/2302.09457)** ![Safety](https://img.shields.io/badge/Safety-87b800)

- [2021/11] **[Fairness-aware Class Imbalanced Learning](https://aclanthology.org/2021.emnlp-main.155/)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![EMNLP](https://img.shields.io/badge/EMNLP-f1b800)

- [2019/02] **[Predictive Inequity in Object Detection](https://arxiv.org/abs/1902.11097)** ![Evaluation](https://img.shields.io/badge/Evaluation-87b800)

- [2017/04] **[Fairness Constraints: Mechanisms for Fair Classification](https://proceedings.mlr.press/v54/zafar17a.html)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![PMLR](https://img.shields.io/badge/PMLR-f1b800)
