# Adversarial Vulnerability

- **[2025/05]** [Adv-CPG: A Customized Portrait Generation Framework with Facial Adversarial Attacks](https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Adv-CPG_A_Customized_Portrait_Generation_Framework_with_Facial_Adversarial_Attacks_CVPR_2025_paper.html) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![CVPR](https://img.shields.io/badge/CVPR-f1b800)
- **[2025/05]** [Adversarial Attacks of Vision Tasks in the Past 10 Years: A Survey](https://arxiv.org/abs/2502.05206) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Survey](https://img.shields.io/badge/Survey-87b800)
- **[2025/05]** [Enhancing the transferability of adversarial attacks via Scale Enriching](https://www.sciencedirect.com/science/article/pii/S0893608025004289) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2025/04]** [RAT: Adversarial Attacks on Deep Reinforcement Agents for Targeted Behaviors](https://ojs.aaai.org/index.php/AAAI/article/view/33696) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![AAAI](https://img.shields.io/badge/AAAI-f1b800) ![Agent](https://img.shields.io/badge/Agent-964B00)
- **[2025/04]** [Adversarial-Inspired Backdoor Defense via Bridging Backdoor and Adversarial Attacks](https://ojs.aaai.org/index.php/AAAI/article/view/33030) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![AAAI](https://img.shields.io/badge/AAAI-f1b800)
- **[2025/04]** [Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion](https://ojs.aaai.org/index.php/AAAI/article/view/32657) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![AAAI](https://img.shields.io/badge/AAAI-f1b800)
- **[2025/03]** [TF-Attack: Transferable and fast adversarial attacks on large language models](https://www.sciencedirect.com/science/article/pii/S0950705125001649) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2025/02]** [Safety at Scale: A Comprehensive Survey of Large Model Safety](https://arxiv.org/abs/2502.05206) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- **[2025/01]** [Enhancing the Transferability of Adversarial Attacks via Multi-Feature Attention](https://ieeexplore.ieee.org/abstract/document/10833658) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)

- **[2024/11]** [Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents](https://arxiv.org/abs/2411.09523) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-964B00) ![Survey](https://img.shields.io/badge/Survey-87b800)
- **[2024/11]** [TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in Vision-Language Models](https://arxiv.org/abs/2411.13136) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2024/10]** [HyGloadAttack: Hard-label black-box textual adversarial attacks via hybrid optimization](https://www.sciencedirect.com/science/article/pii/S089360802400385X) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2024/10]** [FLAT: Flux-Aware Imperceptible Adversarial Attacks on 3D Point Clouds](https://link.springer.com/chapter/10.1007/978-3-031-72658-3_12) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ECCV](https://img.shields.io/badge/ECCV-f1b800)
- **[2024/10]** [AdvQDet: Detecting query-based adversarial attacks with adversarial contrastive prompt tuning](https://arxiv.org/abs/2408.01978) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2024/10]** [CLIP-Guided Generative Networks for Transferable Targeted Adversarial Attacks](https://link.springer.com/chapter/10.1007/978-3-031-73390-1_1) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ECCV](https://img.shields.io/badge/ECCV-f1b800)
- **[2024/09]** [Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks](https://link.springer.com/chapter/10.1007/978-3-031-72775-7_3) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ECCV](https://img.shields.io/badge/ECCV-f1b800)
- **[2024/07]** [Jailbreak Attacks and Defenses Against Large Language Models: A Survey](https://arxiv.org/abs/2407.04295) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- **[2024/06]** [Strong Transferable Adversarial Attacks via Ensembled Asymptotically Normal Distribution Learning](https://openaccess.thecvf.com/content/CVPR2024/html/Fang_Strong_Transferable_Adversarial_Attacks_via_Ensembled_Asymptotically_Normal_Distribution_Learning_CVPR_2024_paper.html) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![CVPR](https://img.shields.io/badge/CVPR-f1b800)
- **[2024/06]** [Transferable Adversarial Attacks on SAM and Its Downstream Models](https://proceedings.neurips.cc/paper_files/paper/2024/hash/9f73d65a4186198152357be871345771-Abstract-Conference.html) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![NeurIPS](https://img.shields.io/badge/NeurIPS-f1b800)
- **[2024/06]** [Mirrorcheck: Efficient adversarial defense for vision-language models](https://arxiv.org/abs/2406.09250) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2024/05]** [Defensive prompt patch: A robust and interpretable defense of llms against jailbreak attacks](https://arxiv.org/abs/2405.20099) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2024/04]** [Defending Language Models Against Image-Based Prompt Attacks via User-Provided Specifications](https://ieeexplore.ieee.org/document/10579532) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Defense](https://img.shields.io/badge/Defense-87b800) ![USENIX](https://img.shields.io/badge/USENIX-f1b800)
- **[2024/02]** [LightPure: Realtime Adversarial Image Purification for Mobile Devices Using Diffusion Models](https://dl.acm.org/doi/10.1145/3636534.3690684) ![AIGC](https://img.shields.io/badge/AIGC-a99cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2024/01]** [MoGU: A framework for enhancing safety of LLMs while preserving their usability](https://openreview.net/pdf?id=SrFbgIjb53) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800) ![Framework](https://img.shields.io/badge/Framework-87b800)
- **[2024/01]** [Mllm-protector: Ensuring mllm's safety without hurting performance](https://arxiv.org/abs/2401.02906) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2024/01]** [One prompt word is enough to boost adversarial robustness for pre-trained vision-language models](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_One_Prompt_Word_is_Enough_to_Boost_Adversarial_Robustness_for_CVPR_2024_paper.pdf) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Defense](https://img.shields.io/badge/Defense-87b800) ![CVPR](https://img.shields.io/badge/CVPR-f1b800)
- **[2023/11]** [Improving alignment and robustness with circuit breakers](https://arxiv.org/abs/2406.04313) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2023/10]** [A mutation-based method for multi-modal jailbreaking attack detection](https://arxiv.org/abs/2310.14442) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2023/07]** [Few-shot adversarial prompt learning on vision-language models](https://arxiv.org/abs/2403.14774) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2023/05]** [Defense-prefix for preventing typographic attacks on clip](https://arxiv.org/abs/2304.04512) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2022/11]** [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2022/10]** [Robust safety classifier against jailbreaking attacks: Adversarial prompt shield](https://aclanthology.org/2024.woah-1.12/) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800) ![ACL](https://img.shields.io/badge/ACL-f1b800)
- **[2022/07]** [Towards efficient adversarial training on vision transformers](https://link.springer.com/chapter/10.1007/978-3-031-19784-0_18) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2022/05]** [Diffusion models for adversarial purification](https://arxiv.org/abs/2205.07460) ![AIGC](https://img.shields.io/badge/AIGC-a99cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2022/05]** [When adversarial training meets vision transformers: Recipes from training to architecture](https://proceedings.neurips.cc/paper_files/paper/2022/file/760b5def8dcb1156aac454e9c0f5f406-Paper-Conference.pdf) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![NeurIPS](https://img.shields.io/badge/NeurIPS-f1b800)
- **[2022/02]** [Patch Vestiges in the Adversarial Examples Against Vision Transformer Can Be Leveraged for Adversarial Detection](https://openreview.net/pdf?id=Y3fjmc2vkKA) ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Defense](https://img.shields.io/badge/Defense-87b800)
- **[2020/08]** [Square attack: a query-efficient black-box adversarial attack via random search](https://link.springer.com/chapter/10.1007/978-3-030-58580-8_29) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2019/06]** [Unrestricted adversarial examples via semantic manipulation](https://arxiv.org/abs/1904.06347) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2018/06]** [Boosting adversarial attacks with momentum](https://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Boosting_Adversarial_Attacks_CVPR_2018_paper.html) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![CVPR](https://img.shields.io/badge/CVPR-f1b800)
- **[2018/02]** [Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples](https://proceedings.mlr.press/v80/athalye18a.html) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ICML](https://img.shields.io/badge/ICML-f1b800)
- **[2017/04]** [Trojaning attack on neural networks](https://www.ndss-symposium.org/wp-content/uploads/2018/02/ndss2018_03A-5_Liu_paper.pdf) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2017/03]** [Practical black-box attacks against machine learning](https://dl.acm.org/doi/10.1145/3052973.3053009) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)

- **[2014/12]** [Explaining and harnessing adversarial examples](https://arxiv.org/abs/1412.6572) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- **[2013/12]** [Intriguing properties of neural networks](https://arxiv.org/abs/1312.6199) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)