- [2025/01] **[Interpretability research of deep learning: A literature survey](https://www.sciencedirect.com/science/article/abs/pii/S1566253524004998)** ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/06] **[Decomposing and interpreting image representations via text in vits beyond CLIP](https://arxiv.org/abs/2406.01583)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- [2024/06] **[Understanding and Mitigating Compositional Issues in Text-to-Image Generative Models](https://arxiv.org/abs/2406.07844)** ![AIGC](https://img.shields.io/badge/AIGC-a99cf4) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- [2024/06] **[Understanding Information Storage and Transfer in Multi-modal Large Language Models](https://arxiv.org/abs/2406.04236)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Evaluation](https://img.shields.io/badge/Evaluation-87b800)
- [2024/04] **[Mechanistic interpretability for AI safety--a review](https://arxiv.org/abs/2404.14082)** ![Survey](https://img.shields.io/badge/Survey-87b800) ![Safety](https://img.shields.io/badge/Safety-87b800)
- [2024/01] **[Interpretable online network dictionary learning for inferring long-range chromatin interactions](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012095)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- [2024/01] **[Using dictionary learning features as classifiers](https://transformer-circuits.pub/2024/features-as-classifiers/index.html)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- [2023/07] **[Analyzing Transformers in Embedding Space](https://aclanthology.org/2023.acl-long.854/)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ACL'23](https://img.shields.io/badge/ACL'23-f1b800)
- [2023/02] **[Evolutionary learning of interpretable decision trees](https://arxiv.org/abs/2012.07723)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- [2023/01] **[Open Problems in Mechanistic Interpretability](https://arxiv.org/abs/2501.16496)** ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2022/12] **[Discovering latent knowledge in language models without supervision](https://arxiv.org/abs/2212.03827)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![NeurIPS'23](https://img.shields.io/badge/NeurIPS'23-f1b800)
- [2022/09] **[Toy models of superposition](https://arxiv.org/abs/2209.10652)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- [2022/02] **[Iseeq: Information seeking question generation using dynamic meta-information retrieval and knowledge graphs](https://ojs.aaai.org/index.php/AAAI/article/view/21319)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![AAAI'22](https://img.shields.io/badge/AAAI'22-f1b800)
- [2022/01] **[Sparse autoencoders find highly interpretable features in language models](https://arxiv.org/abs/2309.08600)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2021/11] **[Explaining by removing: A unified framework for model explanation](https://arxiv.org/abs/2011.14878)** ![Framework](https://img.shields.io/badge/Framework-87b800)
- [2021/08] **[Neural additive models: Interpretable machine learning with neural nets](https://arxiv.org/abs/2004.13912)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![NeurIPS'21](https://img.shields.io/badge/NeurIPS'21-f1b800)
- [2019/05] **[Sparse dictionary learning by dynamical neural networks](https://arxiv.org/abs/1805.08952)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ICLR'19](https://img.shields.io/badge/ICLR'19-f1b800)
- [2018/09] **[Explainable neural computation via stack neural module networks](https://openaccess.thecvf.com/content_ECCV_2018/html/Ronghang_Hu_Explainable_Neural_Computation_ECCV_2018_paper.html)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ECCV'18](https://img.shields.io/badge/ECCV'18-f1b800)
- [2017/08] **[Grad-cam: Visual explanations from deep networks via gradient-based localization](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ICCV'17](https://img.shields.io/badge/ICCV'17-f1b800)
- [2017/08] **[Learning important features through propagating activation differences](https://proceedings.mlr.press/v70/shrikumar17a.html)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ICML'17](https://img.shields.io/badge/ICML'17-f1b800)
- [2017/06] **[A self-interpretable module for deep image classification on small data](https://link.springer.com/article/10.1007/s10489-022-03886-6)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- [2017/06] **[Dynamic routing between capsules](https://arxiv.org/abs/1710.09829)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![NeurIPS'17](https://img.shields.io/badge/NeurIPS'17-f1b800)
- [2017/06] **[Smoothgrad: removing noise by adding noise](https://arxiv.org/abs/1706.03825)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800)
- [2017/06] **[Understanding black-box predictions via influence functions](https://proceedings.mlr.press/v70/koh17a.html)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ICML'17](https://img.shields.io/badge/ICML'17-f1b800)
- [2017/03] **[Axiomatic attribution for deep networks](https://proceedings.mlr.press/v70/sundararajan17a.html)** ![Technical_Solution](https://img.shields.io/badge/Technical_Solution-87b800) ![ICML'17](https://img.shields.io/badge/ICML'17-f1b800)
