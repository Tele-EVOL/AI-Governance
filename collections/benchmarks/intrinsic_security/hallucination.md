# Hallucination

- [2025/02] **[How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild](https://arxiv.org/pdf/2502.12769)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![arXiv](https://img.shields.io/badge/arXiv-f1b800)
- [2025.04] **[HalluLens: LLM Hallucination Benchmark](https://arxiv.org/abs/2504.17550)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL](https://img.shields.io/badge/ACL-f1b800)
- [2024.10] **[FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs](https://arxiv.org/abs/2410.13210)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL](https://img.shields.io/badge/ACL-f1b800)
- [2024.10] **[AVHBench: A Cross-Modal Hallucination Benchmark for Audio-Visual Large Language Models](https://arxiv.org/abs/2410.18325)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![ICLR](https://img.shields.io/badge/ICLR-f1b800)
- [2024.06] **[Evaluating the Quality of Hallucination Benchmarks for Large Vision-Language Models](https://arxiv.org/abs/2406.17115)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![arXiv](https://img.shields.io/badge/arXiv-f1b800)
- [2024.06] **[HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation](https://arxiv.org/abs/2406.07070)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL](https://img.shields.io/badge/ACL-f1b800)
- [2024.06] **[AutoHallusion: Automatic Generation of Hallucination Benchmarks for Vision-Language Models](https://arxiv.org/abs/2406.10900)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![ACL](https://img.shields.io/badge/ACL-f1b800)
- [2024.06] **[ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models](https://arxiv.org/abs/2406.20015)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL](https://img.shields.io/badge/ACL-f1b800)
- [2023.11] **[UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation](https://arxiv.org/abs/2311.15296)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL](https://img.shields.io/badge/ACL-f1b800)
- [2023.10] **[A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection](https://arxiv.org/abs/2310.06498)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL](https://img.shields.io/badge/ACL-f1b800)
- [2023.05] **[HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2305.11747)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL](https://img.shields.io/badge/ACL-f1b800)