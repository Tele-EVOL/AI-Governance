- [2025/01] **[LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models](https://openreview.net/forum?id=Fc_2T8Bmjc)** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![Dataset](https://img.shields.io/badge/Dataset-87b800) ![ICLR-W'25](https://img.shields.io/badge/ICLR--W'25-f1b800)
- [2024/01] **[JailbreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks](https://arxiv.org/abs/2405.08447)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![COLM'24](https://img.shields.io/badge/COLM'24-f1b800)
- [2024/01] **[OODRobustBench: a benchmark and large-scale analysis of adversarial robustness under distribution shift](https://proceedings.mlr.press/v235/li24ae.html)** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![ICML'24](https://img.shields.io/badge/ICML'24-f1b800)
- [2024/01] **[SEED-Bench: Benchmarking Multimodal Large Language Models](https://openaccess.thecvf.com/content/CVPR2024/html/Li_SEED-Bench_Benchmarking_Multimodal_Large_Language_Models_CVPR_2024_paper.html)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![CVPR'24](https://img.shields.io/badge/CVPR'24-f1b800)
- [2024/01] **[AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension](https://aclanthology.org/2024.acl-long.108/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![ACL'24](https://img.shields.io/badge/ACL'24-f1b800)
- [2023/12] **[Revisiting out-of-distribution robustness in nlp: Benchmarks, analysis, and llms evaluations](https://proceedings.neurips.cc/paper_files/paper/2023/hash/e0487a690321c17201b1259648671ccc-Abstract-Datasets_and_Benchmarks.html)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![NeurIPS'23](https://img.shields.io/badge/NeurIPS'23-f1b800)
- [2022/05] **[Truthfulqa: Measuring how models mimic human falsehoods](https://aclanthology.org/2022.acl-long.294/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![ACL'22](https://img.shields.io/badge/ACL'22-f1b800)
- [2021/12] **[Adversarial glue: A multi-task benchmark for robustness evaluation of language models](https://proceedings.neurips.cc/paper/2021/hash/f2205560a5e243b35573426b54780529-Abstract.html)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![NeurIPS'21](https://img.shields.io/badge/NeurIPS'21-f1b800)
- [2021/10] **[The many faces of robustness: A critical analysis of out-of-distribution generalization](https://openaccess.thecvf.com/content/ICCV2021/html/Hendrycks_The_Many_Faces_of_Robustness_A_Critical_Analysis_of_ICCV_2021_paper.html)** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![Dataset](https://img.shields.io/badge/Dataset-87b800) ![ICCV'21](https://img.shields.io/badge/ICCV'21-f1b800)
- [2021/07] **[Wilds: A benchmark of in-the-wild distribution shifts](https://proceedings.mlr.press/v139/koh21a.html)** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![ICML'21](https://img.shields.io/badge/ICML'21-f1b800)
- [2021/06] **[Natural adversarial examples](https://openaccess.thecvf.com/content/CVPR2021/html/Hendrycks_Natural_Adversarial_Examples_CVPR_2021_paper.html)** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![Dataset](https://img.shields.io/badge/Dataset-87b800) ![CVPR'21](https://img.shields.io/badge/CVPR'21-f1b800)
- [2020/08] **[Adversarial nli: A new benchmark for natural language understanding](https://aclanthology.org/2020.acl-main.451/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![ACL'20](https://img.shields.io/badge/ACL'20-f1b800)
- [2019/12] **[Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models](https://proceedings.neurips.cc/paper/2019/hash/91429b140bff44600266f9d774220b33-Abstract.html)** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![Dataset](https://img.shields.io/badge/Dataset-87b800) ![NeurIPS'19](https://img.shields.io/badge/NeurIPS'19-f1b800)
- [2019/06] **[Cycle-consistency for robust visual question answering](https://openaccess.thecvf.com/content_CVPR_2019/html/Shah_Cycle-Consistency_for_Robust_Visual_Youtubeing_CVPR_2019_paper.html)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![Dataset](https://img.shields.io/badge/Dataset-87b800) ![CVPR'19](https://img.shields.io/badge/CVPR'19-f1b800)
- [2019/06] **[Do imagenet classifiers generalize to imagenet?](https://proceedings.mlr.press/v97/recht19a.html)** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![Dataset](https://img.shields.io/badge/Dataset-87b800) ![ICML'19](https://img.shields.io/badge/ICML'19-f1b800)
- [2019/01] **[Benchmarking neural network robustness to common corruptions and perturbations](https://openreview.net/forum?id=HJz6tiCqYm)** ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![Dataset](https://img.shields.io/badge/Dataset-87b800) ![ICLR'19](https://img.shields.io/badge/ICLR'19-f1b800)
